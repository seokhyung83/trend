{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18da1a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import re\n",
    "from kss import kss\n",
    "from konlpy.tag import Mecab\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf04192",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "ref_dic = pd.read_csv('ref_dic.csv')#ref_dic.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1934357",
   "metadata": {},
   "outputs": [],
   "source": [
    "con1 = sqlite3.connect('ensol_news_db.sqlite')\n",
    "cur1 = con1.cursor()\n",
    "cur1.execute(\"select * from mobility\")\n",
    "db_tab = pd.DataFrame(cur1.fetchall())\n",
    "db_tab = db_tab.iloc[:,[1,2,4,5]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b16c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _call_db_info():\n",
    "    return pymysql.connect(\n",
    "        host = 'trend.cb7jqghocrtb.ap-northeast-2.rds.amazonaws.com',\n",
    "        port= 3306,\n",
    "        user = 'root',\n",
    "        password='ensol2020!',\n",
    "        db = 'trend',\n",
    "        charset = 'utf8')\n",
    "\n",
    "\n",
    "conn = _call_db_info()\n",
    "curs = conn.cursor()\n",
    "tmp_insert_sql = \"select * from content where date >= 20210701\"\n",
    "curs.execute(tmp_insert_sql)        \n",
    "tmp_rslt = pd.DataFrame(curs.fetchall())\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "news_tab = tmp_rslt.iloc[:,1:].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b357d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "#print(db_tab.shape, news_tab.shape)\n",
    "#tmp_article= pd.concat((db_tab.iloc[:,3], news_tab.iloc[:,3]))\n",
    "# Test\n",
    "print(news_tab.shape)\n",
    "tmp_article= news_tab.iloc[:,3]\n",
    "\n",
    "tmp_article = tmp_article.drop_duplicates()\n",
    "tmp_article = tmp_article.reset_index(drop=True)\n",
    "print(tmp_article.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "834626e9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_parenthese(str):\n",
    "    items_lst = re.findall('\\(([^)]+)', str) #extracts string in () \n",
    "    newList = [x for x in items_lst if len(x)>=2] # more than 2\n",
    "    return newList\n",
    "\n",
    "def extract_quotes(str):\n",
    "    items_lst = re.findall('\"([^\"]*)\"', str)\n",
    "    return items_lst\n",
    "\n",
    "def parentheses_(tmp_input_sent):    \n",
    "    tmp_input_sent = re.sub(pattern='\\(+', repl=' ', string=tmp_input_sent)#tmp_input_sent = re.sub(pattern='\\(\\(', repl='\\(', string=tmp_input_sent)\n",
    "    tmp_input_sent = re.sub(pattern='\\)+', repl=' ', string=tmp_input_sent)#tmp_input_sent = re.sub(pattern='\\)\\)', repl='\\)', string=tmp_input_sent)\n",
    "    tmp_input_sent = re.sub(pattern=' +', repl=' ', string=tmp_input_sent)\n",
    "    input_sent = re.sub(pattern='\\\\\\\\',   repl='', string=tmp_input_sent)\n",
    "    return input_sent\n",
    "    '''\n",
    "    tmp_sent1, tmp_sent2 = [], []    \n",
    "    s_re = re.compile('\\(')#tmp_sentence[25])#.match('\\(')\n",
    "    e_re = re.compile('\\)')\n",
    "    s_m = [(m.start(0), m.end(0)) for m in s_re.finditer(input_sent)]#tmp_sentence[25])]\n",
    "    e_m = [(m.start(0), m.end(0)) for m in e_re.finditer(input_sent)]#tmp_sentence[25])]\n",
    "    m = []\n",
    "    for i in range(0, len(s_m)):\n",
    "        if s_m[i][1] < e_m[i][0]:\n",
    "            m.append((s_m[i], e_m[i]))\n",
    "        else:\n",
    "            for j in range(i+1, len(e_m)):\n",
    "                if s_m[i][1] < e_m[j][0]:\n",
    "                    m.append((s_m[i], e_m[j]))\n",
    "                    break;                   \n",
    "\n",
    "    if len(m) > 0:\n",
    "        for i in range(0, len(m)):\n",
    "            if i == 0:\n",
    "                tmp_sent1.append(input_sent[:m[i][0][0]])\n",
    "            else :\n",
    "                tmp_sent1.append(input_sent[m[(i-1)][1][1]:m[i][0][0]])                        \n",
    "            tmp_sent2.append(input_sent[m[i][0][1]:m[i][1][0]])\n",
    "        tmp_sent1.append(input_sent[m[-1][1][1]:])    \n",
    "        return ' '.join(tmp_sent1 + tmp_sent2)\n",
    "    else:\n",
    "        return input_sent\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9457b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "step0_ptn= '[\\'\\‘\\’]'\n",
    "step1_ptn= '[\\u00a0\\u3000①②③④⑤⑥⑦⑧⑨⑩』◦※→®↑↓‣★▶■△◇◆▲○●\\{\\}\\[\\]\\/?,+;:‧·ᆞ…》ⓒ|*~`\\\"\"“”!^_<>@\\#&\\\\\\=\\'\\n]'     \n",
    "step2_ptn= '[\\.]' \n",
    "article_sent = []\n",
    "article_ner_l1, article_ner_l2 = [], []\n",
    "\n",
    "for a in range(0, tmp_article.shape[0]):\n",
    "    tmp_a = re.sub(pattern=step0_ptn, repl='\\\"', string=tmp_article.iloc[a])#.replace('\\'‘’', '\\\"')\n",
    "    tmp_a = re.sub(pattern=step1_ptn, repl='', string=tmp_a)\n",
    "    tmp_sentence = kss.split_sentences(tmp_a)\n",
    "    tmp_sentence = [re.sub(pattern=step2_ptn, repl='', string=s) for s in tmp_sentence]\n",
    "    tmp_sentence = [parentheses_(s) for s in tmp_sentence] \n",
    "\n",
    "    ner_sent, ner_tag_l1, ner_tag_l2 = [], [], []\n",
    "    pos_set = ref_dic['명칭'].values.tolist()\n",
    "\n",
    "    for sent in range(0, len(tmp_sentence)):\n",
    "        tmp_ner = []\n",
    "        tmp_sent = re.sub(pattern=' +', repl=' ', string=tmp_sentence[sent])\n",
    "        sent_split = tmp_sent.split(' ')\n",
    "        tmp_sent_n, tmp_sent_a = divmod(len(sent_split), 30)\n",
    "        tmp_mecab_pos = [mecab.pos(w) for w in sent_split]\n",
    "        #tmp_ner = tmp_ner = [t for t in tmp_ner.split(' ') if len(t) >0]#tmp_ner.split(' ')\n",
    "        tmp_ner_l1 = ['O'] * len(sent_split)#len(tmp_ner)\n",
    "        tmp_ner_l2 = ['O'] * len(sent_split)#len(tmp_ner)\n",
    "\n",
    "        for k in range(0 ,len(sent_split)):    \n",
    "            m_pos = [i for i, tmp_me in enumerate(tmp_mecab_pos[k]) if tmp_me[1] == 'NNP']\n",
    "            if len(m_pos) > 0:\n",
    "                for l in range(0, len(m_pos)):#tmp_mecab_pos[4][m_pos[0]][0]\n",
    "                    if tmp_mecab_pos[k][m_pos[l]][0] in pos_set:\n",
    "                        ner_ind = pos_set.index(tmp_mecab_pos[k][m_pos[l]][0])                    \n",
    "                        tmp_ner_l1[k] = ref_dic['대분류'].loc[ner_ind]\n",
    "                        tmp_ner_l2[k] = ref_dic['중분류'].loc[ner_ind]\n",
    "        ner_sent.append((' ').join(sent_split))\n",
    "        ner_tag_l1.append((' ').join(tmp_ner_l1))\n",
    "        ner_tag_l2.append((' ').join(tmp_ner_l2))\n",
    "    article_sent.extend(ner_sent)\n",
    "    article_ner_l1.extend(ner_tag_l1)\n",
    "    article_ner_l2.extend(ner_tag_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4da463e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2991"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c801b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ner_l1_ = [x for a_ner in article_ner_l1 for x in a_ner.split(' ') if x != 'O' and len(x) > 0 ]\n",
    "label_ner_l2_ = [x for a_ner in article_ner_l2 for x in a_ner.split(' ') if x != 'O' and len(x) > 0]\n",
    "tmp_label_ner_l1 = list(set(label_ner_l1_))\n",
    "tmp_label_ner_l2 = list(set(label_ner_l2_))\n",
    "tmp_label_ner_l1.sort()\n",
    "tmp_label_ner_l2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b068200",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ner_l1 = ['UNK']# + tmp_label_ner_l1\n",
    "label_ner_l2 = ['UNK']# + tmp_label_ner_l2\n",
    "for i in tmp_label_ner_l1:\n",
    "    label_ner_l1.extend([i+'-B', i+'-I'])\n",
    "for i in tmp_label_ner_l2:\n",
    "    label_ner_l2.extend([i+'-B', i+'-I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52fa662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train \n",
    "'''\n",
    "with open('LGES_sent_210804.dta', 'wb') as a_sent:\n",
    "    pickle.dump(article_sent, a_sent)\n",
    "with open('LGES_sent_ner_level1_210804.dta', 'wb') as a_sent_l1:\n",
    "    pickle.dump(article_ner_l1, a_sent_l1)   \n",
    "with open('LGES_label_l1_210804.dta', 'wb') as a_label1:\n",
    "    pickle.dump(label_ner_l1, a_label1)\n",
    "'''\n",
    "# Test \n",
    "with open('Test_LGES_sent_210804.dta', 'wb') as a_sent:\n",
    "    pickle.dump(article_sent, a_sent)\n",
    "with open('Test_LGES_sent_ner_level1_210804.dta', 'wb') as a_sent_l1:\n",
    "    pickle.dump(article_ner_l1, a_sent_l1)   \n",
    "with open('Test_LGES_label_l1_210804.dta', 'wb') as a_label1:\n",
    "    pickle.dump(label_ner_l1, a_label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "789ec921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNK',\n",
       " '기술-B',\n",
       " '기술-I',\n",
       " '사건/사고-B',\n",
       " '사건/사고-I',\n",
       " '서비스-B',\n",
       " '서비스-I',\n",
       " '소재-B',\n",
       " '소재-I',\n",
       " '스펙-B',\n",
       " '스펙-I',\n",
       " '이벤트-B',\n",
       " '이벤트-I',\n",
       " '제품-B',\n",
       " '제품-I',\n",
       " '트렌드-B',\n",
       " '트렌드-I']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ner_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9def70b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 605785 개 문장\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'O O O O O O O O O O O O O O O O O O O'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('총 %d 개 문장'%len(article_ner_l1))\n",
    "article_ner_l1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f7bb3fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'artice_ner_l1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-53c7917ed62b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp_total_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martice_ner_l1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'artice_ner_l1' is not defined"
     ]
    }
   ],
   "source": [
    "tmp_total_sent = ' '.join(artice_ner_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e22b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
